{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8Nsqvg-eynJT"},"outputs":[],"source":["!pip install kaggle"]},{"cell_type":"markdown","metadata":{"id":"VrBN80JeFi8J"},"source":["## Load data\n","You can use the API from kaggle or download the data set from kaggle\n","\n","https://www.kaggle.com/datasets/sovitrath/cub-200-bird-species-xml-detection-dataset/code?datasetId=2795899\n"]},{"cell_type":"code","source":[],"metadata":{"id":"rTTrlBEOTiik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Choosing Model\n","\n","Choose an object detection model suitable for detecting birds, such as YOLO, SSD, Faster R-CNN, etc. You can choose to use a pre-trained model or train a new model, depending on your dataset and task requirements."],"metadata":{"id":"nLUH9LjmTW-Z"}},{"cell_type":"code","source":[],"metadata":{"id":"M8na4eMHV1qy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Up4nGsay3XSZ"},"source":["## Preprocessing and Training (optional) (1%)\n","\n","Read the downloaded image data using an appropriate image processing library (e.g. OpenCV, PIL). Next, the XML annotation file is parsed to obtain the location and category information of the bird objects in each image. The images are then scaled and normalized according to the needs of the model, ensuring that the dimensions and numerical range of the input image match the model's expectations. Finally, the data set is divided into a training set and a validation set to evaluate the model performance when training the model.\n","\n","If you choose to train the model, please choose an appropriate loss function (such as mean square error), an optimizer (such as Adam or SGD), and the corresponding training parameters, such as learning rate and batch size. Model training is done using the training set, either transfer learning (initialized with pre-trained model weights) or training from scratch. Finally, the performance of the model is evaluated using the validation set to ensure its generalization ability."]},{"cell_type":"code","source":[],"metadata":{"id":"SPI529jjUysp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSfzY7gdD32c"},"source":["## Evaluate Model Performance (1%)\n","\n","Use the trained model to detect objects on the validation set, and calculate evaluation indicators such as average precision (AP) to evaluate the performance of the model. This helps confirm the model's accuracy and generalization ability on new data\n"]},{"cell_type":"code","source":[],"metadata":{"id":"zKtAbwIoVMYw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8HMmgp4n7dd_"},"source":["## Inference and Visualization (3%)\n","For 5 test images, the trained model is used for inference, showing the predicted bounding boxes and comparing with the actual annotated ground truth. This helps visualize how the model performs in real-world situations and ensures it correctly detects and localizes avian objects."]},{"cell_type":"code","source":[],"metadata":{"id":"tJpZC0ujVLDb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}