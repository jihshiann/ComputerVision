{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNhjnRPvQj9RfFxaqr5u3I8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Regularisation in Keras - Part 2 - With Regularisation**\n","### **First we train a CNN on the Fashion-MNIST Dataset usng NO Regularisation Methods**\n","\n","\n","1. Loading, Inspecting and Visualising our data\n","2. Preprocessing our data and defining our **Data Augmentation**\n","3. Build a Simple CNN with Regularisation\n","  - L2 Regularisation\n","  - Data Augmentation\n","  - Dropout\n","  - BatchNorm\n","4. Train our CNN with Regularisation\n","\n"],"metadata":{"id":"hIprLW1zp6Sv"}},{"cell_type":"markdown","source":["# **1. Loading, Inspecting and Visualising our data**"],"metadata":{"id":"I2nRLPgoqFJ4"}},{"cell_type":"code","source":["# We load our data directly from the included datasets in tensorflow.keras\n","from tensorflow.keras.datasets import fashion_mnist\n","\n","# loads the Fashion-MNIST training and test dataset\n","(x_train, y_train), (x_test, y_test)  = fashion_mnist.load_data()\n","\n","# Our Class Names, when loading data from .datasets() our classes are integers\n","classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress',\n","           'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkWv9Ex0qBCj","executionInfo":{"status":"ok","timestamp":1696305099245,"user_tz":-480,"elapsed":4227,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"21f1986f-a7bb-4cd7-b2f5-9baecf264bc0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Check to see if we're using the GPU\n","from tensorflow.python.client import device_lib\n","\n","print(device_lib.list_local_devices())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKznUCzrqG5O","executionInfo":{"status":"ok","timestamp":1696305102634,"user_tz":-480,"elapsed":3,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"fe7957c9-9339-4114-ad8c-e81a169e80eb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 2882668922592385172\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14357954560\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 17006103299379847977\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}]},{"cell_type":"markdown","source":["# **2. Data Preprocessing using ImageDataGenerator**\n","\n","First we reshape and change our data types as we had done previously."],"metadata":{"id":"KBOAPpO8qSd9"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from matplotlib import pyplot\n","from tensorflow.keras import backend as K\n","\n","# Reshape our data to be in the format [number of samples, width, height, color_depth]\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","\n","# Change datatype to float32\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')"],"metadata":{"id":"4h97AzfJqJ2i","executionInfo":{"status":"ok","timestamp":1696305110008,"user_tz":-480,"elapsed":2,"user":{"displayName":"楊景明","userId":"02385702773581765739"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**We gather our image size, shape and Normalize our Test Data**\n","\n","We will use the ImageDataGenerator to Normalize and provide Data Augmentations for our **Training Data**."],"metadata":{"id":"Jj_5-ykbqnvJ"}},{"cell_type":"code","source":["# Lets store the number of rows and columns\n","img_rows = x_train[0].shape[0]\n","img_cols = x_train[0].shape[1]\n","\n","# store the shape of a single image\n","input_shape = (img_rows, img_cols, 1)\n","\n","# Normalize our data between 0 and 1\n","x_test /= 255.0"],"metadata":{"id":"6ZnKIKAhqdfX","executionInfo":{"status":"ok","timestamp":1696305191385,"user_tz":-480,"elapsed":269,"user":{"displayName":"楊景明","userId":"02385702773581765739"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### **One Hot Encode our Labels**"],"metadata":{"id":"5FbXH8-Aq1dc"}},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","# Now we one hot encode outputs\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Let's count the number columns in our hot encoded matrix\n","print (\"Number of Classes: \" + str(y_test.shape[1]))\n","\n","num_classes = y_test.shape[1]\n","num_pixels = x_train.shape[1] * x_train.shape[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAfMHm5qqxbX","executionInfo":{"status":"ok","timestamp":1696305214871,"user_tz":-480,"elapsed":3,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"e41fb594-46bc-41f0-f774-656ca876479b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Classes: 10\n"]}]},{"cell_type":"markdown","source":["# **3. Building Our Model**\n","\n","This is the same CNN we used previously for the MNIST classification project."],"metadata":{"id":"vU_kgP7Eq4mD"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras import regularizers\n","\n","L2 = 0.001\n","\n","# create model\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 kernel_regularizer = regularizers.l2(L2), # or L1\n","                 input_shape=input_shape))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = regularizers.l2(L2)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu',kernel_regularizer = regularizers.l2(L2)))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.SGD(0.001, momentum=0.9),\n","              metrics = ['accuracy'])\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_qIxpMDq266","executionInfo":{"status":"ok","timestamp":1696307647809,"user_tz":-480,"elapsed":296,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"78fde2d0-8754-41dc-9ac4-3f97d17dc607"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 26, 26, 32)        128       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 24, 24, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 9216)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               1179776   \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 1200266 (4.58 MB)\n","Trainable params: 1200074 (4.58 MB)\n","Non-trainable params: 192 (768.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","source":["# **Training Our Model**"],"metadata":{"id":"9-GYQ6VYrG7k"}},{"cell_type":"code","source":["# Define Data Generator for Augmentation\n","train_datagen = ImageDataGenerator(\n","        rescale = 1./255,\n","        rotation_range=10,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1,\n","        shear_range=0.1,\n","        zoom_range=0.1,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","\n","# Here we fit the data generator to some sample data.\n","#train_datagen.fit(x_train)\n","\n","batch_size = 32\n","epochs = 20 # use more epochs\n","\n","# Fit the model\n","# Notice we use train_datagen.flow, this takes data & label arrays, generates batches of augmented data.\n","history = model.fit(train_datagen.flow(x_train, y_train, batch_size = batch_size),\n","                              epochs = epochs,\n","                              validation_data = (x_test, y_test),\n","                              verbose = 1)\n","\n","# We obtain our accuracy score using the evalute function\n","# Score holds two values, our Test loss and Accuracy\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ohp9UKKq66B","executionInfo":{"status":"ok","timestamp":1696308272969,"user_tz":-480,"elapsed":623485,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"c2ebcfb4-3bc1-4912-8d30-d8b95d66f3d5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1875/1875 [==============================] - 31s 16ms/step - loss: 1.0131 - accuracy: 0.7310 - val_loss: 0.7671 - val_accuracy: 0.8134\n","Epoch 2/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.8332 - accuracy: 0.7894 - val_loss: 0.6898 - val_accuracy: 0.8450\n","Epoch 3/20\n","1875/1875 [==============================] - 29s 16ms/step - loss: 0.7701 - accuracy: 0.8077 - val_loss: 0.6367 - val_accuracy: 0.8578\n","Epoch 4/20\n","1875/1875 [==============================] - 28s 15ms/step - loss: 0.7227 - accuracy: 0.8217 - val_loss: 0.5942 - val_accuracy: 0.8718\n","Epoch 5/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.6806 - accuracy: 0.8337 - val_loss: 0.5683 - val_accuracy: 0.8747\n","Epoch 6/20\n","1875/1875 [==============================] - 29s 16ms/step - loss: 0.6509 - accuracy: 0.8380 - val_loss: 0.5409 - val_accuracy: 0.8795\n","Epoch 7/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.6222 - accuracy: 0.8449 - val_loss: 0.5349 - val_accuracy: 0.8801\n","Epoch 8/20\n","1875/1875 [==============================] - 29s 15ms/step - loss: 0.6006 - accuracy: 0.8508 - val_loss: 0.5100 - val_accuracy: 0.8852\n","Epoch 9/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.5812 - accuracy: 0.8531 - val_loss: 0.5199 - val_accuracy: 0.8743\n","Epoch 10/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.5585 - accuracy: 0.8590 - val_loss: 0.5361 - val_accuracy: 0.8700\n","Epoch 11/20\n","1875/1875 [==============================] - 31s 16ms/step - loss: 0.5461 - accuracy: 0.8602 - val_loss: 0.4714 - val_accuracy: 0.8898\n","Epoch 12/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.5289 - accuracy: 0.8662 - val_loss: 0.4668 - val_accuracy: 0.8888\n","Epoch 13/20\n","1875/1875 [==============================] - 31s 16ms/step - loss: 0.5157 - accuracy: 0.8667 - val_loss: 0.5084 - val_accuracy: 0.8693\n","Epoch 14/20\n","1875/1875 [==============================] - 33s 17ms/step - loss: 0.5038 - accuracy: 0.8688 - val_loss: 0.4272 - val_accuracy: 0.9005\n","Epoch 15/20\n","1875/1875 [==============================] - 31s 17ms/step - loss: 0.4918 - accuracy: 0.8727 - val_loss: 0.4356 - val_accuracy: 0.8910\n","Epoch 16/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.4820 - accuracy: 0.8735 - val_loss: 0.4223 - val_accuracy: 0.8989\n","Epoch 17/20\n","1875/1875 [==============================] - 29s 16ms/step - loss: 0.4728 - accuracy: 0.8746 - val_loss: 0.4029 - val_accuracy: 0.8986\n","Epoch 18/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.4649 - accuracy: 0.8768 - val_loss: 0.4009 - val_accuracy: 0.9010\n","Epoch 19/20\n","1875/1875 [==============================] - 30s 16ms/step - loss: 0.4570 - accuracy: 0.8766 - val_loss: 0.3917 - val_accuracy: 0.9034\n","Epoch 20/20\n","1875/1875 [==============================] - 29s 16ms/step - loss: 0.4514 - accuracy: 0.8794 - val_loss: 0.3963 - val_accuracy: 0.8998\n","Test loss: 0.3963181674480438\n","Test accuracy: 0.8998000025749207\n"]}]},{"cell_type":"markdown","source":["Train for more epochs, or try using data augmentation technique ony by one."],"metadata":{"id":"QgKr_sCg1lZA"}},{"cell_type":"code","source":[],"metadata":{"id":"-WYMPD2errEu"},"execution_count":null,"outputs":[]}]}