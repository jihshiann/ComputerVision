# -*- coding: utf-8 -*-
"""homework_2_20231221.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rUDm7UZzvrw7jTCAZnpfdngXbdxi-0fS
"""

!pip install kaggle

import tensorflow as tf

if tf.test.gpu_device_name():
    print("GPU : {}".format(tf.test.gpu_device_name()))
else:
    print("NO")

"""## Load data
You can use the API from kaggle or download the data set from kaggle

https://www.kaggle.com/datasets/sovitrath/cub-200-bird-species-xml-detection-dataset/code?datasetId=2795899

"""

from google.colab import files

upload kaggle.json
uploaded = files.upload()


!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d sovitrath/cub-200-bird-species-xml-detection-dataset

# 解壓縮
import zipfile
with zipfile.ZipFile('cub-200-bird-species-xml-detection-dataset.zip', 'r') as zip_ref:
    zip_ref.extractall("cub-200-bird-species-xml-detection-dataset")

#trainImg_folder = '/content/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/train_images'
#trainLabel_folder = '/content/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/train_labels'
#validImg_folder = '/content/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/valid_images'
#validLabel_folder = '/content/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/valid_labels'

trainImg_folder = '/kaggle/input/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/train_images'
trainLabel_folder = '/kaggle/input/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/train_labels'
validImg_folder = '/kaggle/input/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/valid_images'
validLabel_folder = '/kaggle/input/cub-200-bird-species-xml-detection-dataset/cub_200_2011_xml/valid_labels'

import xml.etree.ElementTree as ET
import os

def count_classes(xml_folder):
    classes = set()

    for xml_file in os.listdir(xml_folder):
        if xml_file.endswith('.xml'):
            tree = ET.parse(os.path.join(xml_folder, xml_file))
            root = tree.getroot()

            for member in root.findall('object'):
                classes.add(member.find('name').text)

    return len(classes), classes


total_classes, class_names = count_classes(validLabel_folder)

print("總共有 {} 個類別。".format(total_classes))
print("類別名稱:", class_names)

"""##Choosing Model

Choose an object detection model suitable for detecting birds, such as YOLO, SSD, Faster R-CNN, etc. You can choose to use a pre-trained model or train a new model, depending on your dataset and task requirements.
"""

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Reshape
from tensorflow.keras.layers import Conv2D, Reshape, Concatenate

def create_ssd_model():
    base_model = MobileNetV2(weights='imagenet', include_top=False)

    # 凍結基礎層權重
    for layer in base_model.layers:
        layer.trainable = False

    # 新增自定義層進行物體檢測
    x = base_model.output

    # 預測邊界框的層
    x = Conv2D(4, (3, 3), padding='same')(x)  # 4 是邊界框坐標
    x = Reshape((-1, 4))(x)

    model = Model(inputs=base_model.input, outputs=x)
    return model

ssd_model = create_ssd_model()
ssd_model.summary()

"""## Preprocessing and Training (optional) (1%)

Read the downloaded image data using an appropriate image processing library (e.g. OpenCV, PIL). Next, the XML annotation file is parsed to obtain the location and category information of the bird objects in each image. The images are then scaled and normalized according to the needs of the model, ensuring that the dimensions and numerical range of the input image match the model's expectations. Finally, the data set is divided into a training set and a validation set to evaluate the model performance when training the model.

If you choose to train the model, please choose an appropriate loss function (such as mean square error), an optimizer (such as Adam or SGD), and the corresponding training parameters, such as learning rate and batch size. Model training is done using the training set, either transfer learning (initialized with pre-trained model weights) or training from scratch. Finally, the performance of the model is evaluated using the validation set to ensure its generalization ability.
"""

import tensorflow as tf
from tensorflow.keras.utils import Sequence
import os
import cv2
import numpy as np
import xml.etree.ElementTree as ET

def resize_box(box, orig_size, target_size):
    x_scale = target_size[0] / orig_size[0]
    y_scale = target_size[1] / orig_size[1]

    resized_box = [
        int(box[0] * x_scale),
        int(box[1] * y_scale),
        int(box[2] * x_scale),
        int(box[3] * y_scale)
    ]
    return resized_box

class BirdDataset(Sequence):
    def __init__(self, image_folder, label_folder, batch_size, img_size=(224, 224)):
        self.image_folder = image_folder
        self.label_folder = label_folder
        self.batch_size = batch_size
        self.img_size = img_size
        self.image_filenames = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]

    def __len__(self):
        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]
        images = []
        labels = []

        for file_name in batch_x:
            img_path = os.path.join(self.image_folder, file_name)  # 加載圖像的路徑
            image = self.load_image(img_path)  # 加載並處理圖像
            images.append(image)  # 添加處理後的圖像到列表

            label_path = os.path.join(self.label_folder, file_name.replace('.jpg', '.xml'))
            label = self.parse_xml(label_path)
            labels.append(label)

        return np.array(images), np.array(labels)

    def load_image(self, path):
        image = cv2.imread(path)
        image = cv2.resize(image, self.img_size)
        image = image / 255.0  # Normalize to [0, 1]
        return image

    def parse_xml(self, xml_file):
        tree = ET.parse(xml_file)
        root = tree.getroot()

        # 獲取原始圖像尺寸
        for size in root.findall('size'):
            orig_width = int(size.find('width').text)
            orig_height = int(size.find('height').text)

        orig_size = (orig_width, orig_height)
        target_size = self.img_size

        boxes = []
        for member in root.findall('object'):
            bndbox = member.find('bndbox')
            xmin = int(bndbox.find('xmin').text)
            ymin = int(bndbox.find('ymin').text)
            xmax = int(bndbox.find('xmax').text)
            ymax = int(bndbox.find('ymax').text)

            box = [xmin, ymin, xmax, ymax]
            resized_box = resize_box(box, orig_size, target_size)
            boxes.append(resized_box)

        return boxes

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy

# 設定學習率
learning_rate = 0.001

# 使用Adam優化器，並設定學習率
adam_optimizer = Adam(learning_rate=learning_rate)


# 使用數據生成器
batch_size = 32  # 根據您的記憶體限制選擇一個合適的數值
train_dataset = BirdDataset(trainImg_folder, trainLabel_folder, batch_size)
valid_dataset = BirdDataset(validImg_folder, validLabel_folder, batch_size)


# 在編譯模型時使用自定義損失函數
ssd_model.compile(optimizer=adam_optimizer, loss='mean_squared_error')


# 訓練模型
epochs = 1  # 可以調整訓練的輪次
ssd_model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset)

"""## Evaluate Model Performance (1%)

Use the trained model to detect objects on the validation set, and calculate evaluation indicators such as average precision (AP) to evaluate the performance of the model. This helps confirm the model's accuracy and generalization ability on new data

"""

# 評估模型
performance = ssd_model.evaluate(valid_dataset)
print("模型性能:", performance)

"""## Inference and Visualization (3%)
For 5 test images, the trained model is used for inference, showing the predicted bounding boxes and comparing with the actual annotated ground truth. This helps visualize how the model performs in real-world situations and ensures it correctly detects and localizes avian objects.
"""

import numpy as np

def non_max_suppression(boxes, iou_threshold=0.01):
    if len(boxes) == 0:
        return []

    # 将框的坐标转换为浮点数（如果它们不是）
    if boxes.dtype.kind == "i":
        boxes = boxes.astype("float")

    # 初始化选中框的列表
    pick = []

    # 获取边界框坐标
    x1 = boxes[:,0]
    y1 = boxes[:,1]
    x2 = boxes[:,2]
    y2 = boxes[:,3]

    # 计算边界框面积并排序
    area = (x2 - x1) * (y2 - y1)
    idxs = np.argsort(y2)

    while len(idxs) > 0:
        last = len(idxs) - 1
        i = idxs[last]
        pick.append(i)

        # 找到剩余框与当前框的最大交集坐标
        xx1 = np.maximum(x1[i], x1[idxs[:last]])
        yy1 = np.maximum(y1[i], y1[idxs[:last]])
        xx2 = np.minimum(x2[i], x2[idxs[:last]])
        yy2 = np.minimum(y2[i], y2[idxs[:last]])

        # 计算宽度和高度，以及交集面积
        w = np.maximum(0, xx2 - xx1)
        h = np.maximum(0, yy2 - yy1)
        overlap = (w * h) / area[idxs[:last]]

        # 删除所有与当前框重叠度高于阈值的框
        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > iou_threshold)[0])))

    # 返回最终选中的边界框
    return boxes[pick].astype("int")




def iou(box1, box2):
    # 計算交集區域
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    intersection_area = max(0, x2 - x1) * max(0, y2 - y1)

    # 計算各自區域
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])

    # 計算並集區域
    union_area = box1_area + box2_area - intersection_area

    # 計算交並比
    return intersection_area / union_area if union_area != 0 else 0

import matplotlib.pyplot as plt
import matplotlib.patches as patches

def visualize_predictions(image, predictions, ground_truth):
    fig, ax = plt.subplots(1)
    ax.imshow(image)

    # 打印应用NMS之前的框数量
    print("框的数量（应用NMS之前）:", len(predictions))

    selected_boxes = non_max_suppression(predictions, iou_threshold=0.3)  # 尝试降低这个阈值

    # 打印应用NMS之后的框数量
    print("框的数量（应用NMS之后）:", len(selected_boxes))

    for box in selected_boxes:
        rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

    for truth in ground_truth:
        rect = patches.Rectangle((truth[0], truth[1]), truth[2] - truth[0], truth[3] - truth[1], linewidth=2, edgecolor='g', facecolor='none')
        ax.add_patch(rect)

    plt.show()

num_images_to_visualize = 5
count = 0

for batch_images, batch_labels in valid_dataset:
    predictions = ssd_model.predict(batch_images)

    for i in range(len(batch_images)):
        # batch_labels[i] 應該包含真實標籤的邊界框
        # predictions[i] 應該包含預測的邊界框
        # 如果 batch_labels 或 predictions 不是 NumPy 陣列，您可能需要將它們轉換過來
        visualize_predictions(batch_images[i], predictions[i], batch_labels[i])
        count += 1

        if count >= num_images_to_visualize:
            break

    if count >= num_images_to_visualize:
        break